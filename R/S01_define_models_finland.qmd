---
title: "Quantitative biodiversity modelling for finance and companies"
subtitle: "Project 1: compare metrics"
author: 
  - name: "Carlos Muñoz"
    email: carlos_jair.munoz@cec.lu.se
    affiliations: 
      - ref: CEC

affiliations:
  - id: CEC
    name: Centre for Environmental and Climate Science, Lund University
    department: Centre for Environmental and Climate Science 
    address: Kontaktvägen 10
    city: Lund
    postal-code: 22362
    url: https://www.cec.lu.se/home
   
format:
  html:
    theme: cosmo # try other themes from https://quarto.org/docs/output-formats/html-themes.html
    toc: true # this will enable Table of Contents
    code-fold: false #try changing it and see what happens
    embed-resources: true # this is so your file would embed all images. 
    output-dir: "../quarto_reports/"  
  pdf: default
  docx: default

execute: 
  echo: true    #use to show/hide R-code in the report
  cache: false
number-sections: true #sectioner can be automatically numbered
title-block-banner: true
---

## Introduction

### General framework

-   Biodiversity is declining at an alarming rate, faster than ever in human history (Barnosky et al., 2011; Ceballos et al., 2015).
-   Economic activity is at the core of the biodiversity crisis, but biodiversity loss also represents a significant physical threat, reputational and regulatory risk to business and financial activities.
-   BIOPATH (Sweden) seeks to develop innovative approaches to integrate biodiversity considerations into financial and business decision-making to halt and reverse biodiversity loss.

### Biodiversity metrics

-   Biodiversity databases are the foundation for effective management strategies, but data alone isn't enough to stop biodiversity loss. We need to turn this data into useful information. This means using some way of biodiversity measurement to move activities from harming nature to being neutral or even positive.
-   Burgess and colleagues (2024) identified 573 metrics developed to inform decision-making related to biodiversity.
-   What metrics should be used?

#### A Tension

-   Business Perspective: Need for accessible, cost-effective and standardized. Importance of simplicity.
-   Natural scientific Perspective:Reflect ecological complexity.Capture multiple dimensions.
-   Maybe a set instead of only one silver bullet

### Challenge

-   The heart of the matter with biodiversity state metrics is how biodiversity change is interpreted and, consequently, how choices are made may be significantly impacted by the selection and response of biodiversity measures (Silvestro et al., 2023). It is critical to understand how different measures respond to changes, which metrics are particularly sensitive to early signals of biodiversity loss, and which metrics respond to changes consistently.
-   How transparently, efficiently, and credibly these measures capture the state and changes on multiple dimensions of biodiversity?

## Objective

To compare biodiversity metrics using quantitative models to assess how accurately they reflect biodiversity states and trends in different biodiversity change scenarios.

-   Birds as focal study taxon
-   Biodiversity change because change of habitat: forestry management scenarios

**THERE IS A NOTORIOUS GAP ABOUT WHY TO USE BIRDS AND WHY FOREST**

## Rol of Hmsc

An Hmsc model provides predictions at the species-community level. This enables the spatial representation of biodiversity to analyse and evaluate biodiversity metrics’ performance and variation through environmental and spatial gradients while counting for uncertainties.

## Data

```{r, setup}
knitr::opts_knit$set(root.dir = "c:/Users/Carlos Munoz/Documents/Ph.D/6_courses/2025_I_comparative_metrics/")
```

```{r}
#| message: false
#| warning: false

library(Hmsc)
library(tidyverse)
library(data.table)
library(terra)
library(sf)
library(maps)
library(ape)
library(taxize)
library(remotes)
library(phytools)
library(openxlsx)
library(tidyterra)
library(viridis)
library(lwgeom)
library(ggrepel)
```

```{r}
options("GDAL_DATA" = Sys.getenv("GDAL_DATA")) # Ensure GDAL_DATA is set if needed
options("OSR_USE_NON_DEPRECATED" = "NO")
```


```{r}
transform_Y_to_abunCpres <- function(data) {
  data |> mutate(across(everything(), ~ ifelse(. == 0, NA, scale(log(.)))))
}
```


```{r}
set.seed(11072024)
```


```{r}
# coordinates 
coords <- st_read("data/fbs/vakiolinja/Vakiolinjat_routes.geojson")

# routes (names and dates)
routes <- read.csv("data/fbs/vakiolinja/vakiolinja1_20250626.csv")

# occurrences by route (spp key, and counts in points and lines)

occurr_route <- read.csv("data/fbs/vakiolinja/vakiolinja2_20250626.csv") 

# occurrences by section route (spp key, and counts in points and lines)

occurr_sect_route <- read.csv("data/fbs/vakiolinja/vakiolinja3_20250626.csv") 


```

```{r}
# late Spring/Summer routes from 2009-2021

routes <- routes |> 
  mutate(out_date = ifelse((month < 5 | month > 7 | year < 2009 | year > 2021), 1, 0 ))

event_ids_to_match <- routes |> 
  filter(out_date == 1) |> 
  pull(eventId) |> 
  unique()

occurr_route <- occurr_route |> 
  mutate(out_date = as.numeric(eventId %in% event_ids_to_match))

occurr_sect_route <- occurr_sect_route |> 
  mutate(out_date = as.numeric(eventId %in% event_ids_to_match))

# are there routes that we have to remove because no data?
routes |> 
  group_by(vakio) |> 
  summarise(total_events = n(), out_count = sum(out_date == 1)) |> 
  mutate(vakio_out = as.numeric(total_events == out_count)) |> 
  filter(vakio_out == 1)
  ##  No need to filter coords
  
# Filtering routes and routes

routes <- routes |> 
  filter(out_date != 1)

occurr_route <- occurr_route |> 
  filter(out_date != 1)

occurr_sect_route <- occurr_sect_route |> 
  filter(out_date != 1)


```


```{r}
# exploring spatial information on valid eventids (inside season and years) with biotope information

no_biotope <- occurr_sect_route |> 
  filter(biotope == "")
no_biotope <- (table(no_biotope$vakio, no_biotope$year) > 0) 

# a) what percentage of routes have no biotope information or subsection information
# b) of those without information how many times have been without biotope info?

no_biotope_routes <- no_biotope |> 
  rowSums()

## a 
length(no_biotope_routes)/566*100

## b
table(no_biotope_routes)/566*100

no_biotope_routes_df <- data.frame(
  vakio = names(no_biotope_routes),
  times_missing = no_biotope_routes
)

# how many routes have no had biotope or subsection info each year?
# what percentege of routes that were sample each year dont have biotope or subsection info?

no_biotope_years <- no_biotope |> 
  colSums()

sample_by_year <- occurr_sect_route |> 
  filter(year != 2019) |> 
  group_by(year) |> 
  summarize(sample_routes = length(unique(vakio)))

percent_sample_no_biotope <- no_biotope_years/sample_by_year$sample_routes*100

hist(percent_sample_no_biotope)

# how many of the biotope and subsection information is missing? Is all the route?

occurr_sect_route |> 
  group_by(year, vakio) |> 
  summarise(total_rows = n(), count = sum(biotope == "")) |> 
  filter(count != 0) |> 
  mutate(vakio = as.factor(vakio)) |> 
  pivot_longer(cols = c(total_rows, count), names_to = "category", values_to = "rows") |> 
  ggplot(aes(x = vakio, y = rows, fill = category ))+
  geom_col(position="dodge") + 
  coord_flip() + 
  facet_wrap(vars(year), scales="free")

```

```{r}
coords_nm <- str_split(coords$name, pattern = ", ", simplify = T) |> 
  as.data.frame()
names(coords_nm) <- c("vakio", "str1", "str2", "numer")

coords <- bind_cols(coords, coords_nm) |> 
  left_join(y = no_biotope_routes_df, by = "vakio") |> 
  mutate(vakio = as.numeric(vakio), times_missing = as.factor(ifelse(is.na(times_missing), 0, times_missing))) |> 
  arrange(vakio)

write_sf(coords, "data/fbs/coords.gpkg", delete_layer = T)

```

```{r}

fin <- st_as_sf(map(database = "world", regions = "finland", plot = FALSE, fill = TRUE))

lvls <- levels(coords$times_missing)
turbo_discrete_colors <- viridis_pal(option = "turbo")(n = length(lvls) - 1)
custom_colors <- c(
  "0" = "gray",
  setNames(turbo_discrete_colors, lvls[lvls != "0"])
)

table(coords$times_missing)

coords |> 
  ggplot() +
  geom_sf(data = fin) +
  geom_sf(aes(color = times_missing)) +
  scale_color_manual(values = custom_colors, name = "times_missing", drop = FALSE)

```

```{r}

# transforming raw data
## calculating polygon information for biotope line

route_i <- coords |> 
  filter(vakio == 113) |> 
  st_transform(crs = "EPSG:2393") 

biotope_route_i <- occurr_sect_route |> 
  filter(year == 2011, vakio == 113) |> 
  select(biotopeStripId, startMeters, endMeters, meters, biotope, biotopeSpecifier) |> 
  distinct() |> 
  mutate(r_startMeters = startMeters/as.numeric(st_length(route_i)), r_endMeters = endMeters/as.numeric(st_length(route_i)))

split_route_i <- list()

for(r in 1:nrow(biotope_route_i)){
  split_route_i[[r]] <- st_linesubstring(route_i, from = biotope_route_i$r_startMeters[r], to = biotope_route_i$r_endMeters[r])
}

split_route_i <- do.call("rbind", split_route_i) |> 
  bind_cols(biotope_route_i) |> 
  st_buffer(dist = 150, endCapStyle = "FLAT", joinStyle = "BEVEL")

# if we keep this it is needed to extent the loop to all years and routes

```


```{r}
## species info

sppY <- unique(occurr_route$scientificName)

run <-  F

if(run == T){
  tax_raw <- taxize::classification(sppY, db = "gbif")
  missing_index <- which(is.na(tax_raw))
  missing <- sppY[missing_index]
  tax_raw <- tax_raw[-missing_index]
  missing_tax <- taxize::classification(missing, db = "itis")
  tax_raw <- c(tax_raw, missing_tax)
  saveRDS(object = tax_raw, file = "data/fbs/tax_raw_data.rds")
}else{
  tax_raw <- readRDS(file = "data/fbs/tax_raw_data.rds")
}

tax_i <- purrr::map2(tax_raw, names(tax_raw), .f = function(.x, .y){
  if(!is.logical(.x)){
    current_df <- as.data.frame(.x)
    n.r <- nrow(current_df)
    cols <- current_df$rank
    high_rank <- cols[n.r]
    info <- as.list(current_df$name)
    names(info) <- cols
    info <- as.data.frame(info)
    info$id <- as.integer(current_df$id[n.r])
    info$input_name <- .y  
    info$high_rank <- high_rank
  }
  return(info)
})

tax_i <- list_rbind(tax_i) |> 
  relocate(subfamily, .after = family) |> 
  relocate(subspecies, .after = species) |> 
  select(-c("subkingdom", "infrakingdom", "subphylum", "infraphylum", "superclass",
            "subclass", "infraclass", "suborder", "superfamily"))

index_odo <- which(tax_i$subfamily == "Odocoileinae")
tax_i$kingdom[index_odo] <- "Animalia"
tax_i$phylum[index_odo] <- "Chordata"
tax_i$class[index_odo] <- "Mammalia"
tax_i$order[index_odo] <- "Artiodactila"
tax_i$family[index_odo] <- "Cervidae"

# What classes do we have?
class_data <- tax_i |>
  count(class, name = "n")  |> 
  mutate(
    value = n / sum(n),
    csum = rev(cumsum(rev(value))),
    pos = value / 2 + lead(csum, 1),
    pos = if_else(is.na(pos), value / 2, pos),
    label = paste0(class, "\n", scales::percent(value))
  )

ggplot(class_data, aes(x = "", y = value, fill = fct_inorder(class))) +
  geom_col(width = 1, color = "white", linewidth = 0.5) +
  coord_polar(theta = "y") +
  labs(title = "Distribution of Taxonomic Labels by Class", fill = "Class") +
  theme_void() +
  geom_label_repel(aes(y = pos, label = label),
                   size = 3.5,
                   nudge_x = 1,
                   show.legend = FALSE,
                   force = 1,
                   max.overlaps = Inf,
                   box.padding = 0.5,
                   point.padding = 0.5
                   ) +
  guides(fill = guide_legend(title = "Class")) +
  theme(plot.title = element_text(hjust = 0.5, size = 14, face = "bold"))

# Which is the distribution of birds in the data set? (using order)
aves_order_data_barplot <- tax_i |>
  filter(class == 'Aves') |>
  count(order, name = 'n') |>
  mutate(percentage = n / sum(n)) |>
  arrange(desc(n))

ggplot(aves_order_data_barplot, aes(x = reorder(order, -n), y = n, fill = order)) +
  geom_col(color = 'black') +
  labs(title = 'Distribution of Taxonomic Labels by Order (Class: Aves)',
       x = 'Order',
       y = 'Count',
       fill = 'Order') +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(hjust = 0.5, size = 14, face = 'bold')) +
  geom_text(aes(label = n), vjust = -0.5, size = 3) 

# What kind of taxonomic labels do we have?
high_rank_data_barplot <- tax_i |>
  count(high_rank, name = 'n') |>
  mutate(percentage = n / sum(n)) |>
  arrange(desc(n))

ggplot(high_rank_data_barplot, aes(x = reorder(high_rank, -n), y = n, fill = high_rank)) +
  geom_col(color = 'black') +
  labs(title = 'Distribution of Taxonomic Labels by High Rank',
       x = 'High Rank',
       y = 'Count',
       fill = 'High Rank') +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(hjust = 0.5, size = 14, face = 'bold')) +
  geom_text(aes(label = n), vjust = -0.5, size = 3)

## From those that aren't species, how many of them are birds?

tax_i |> 
  filter(high_rank != "species", high_rank != "subspecies") |> 
  count(class, high_rank, name = 'n') |> 
  gt()
  


```


From `r min(years)`to `r max(years)` (`r max(years) - min(years)` years), the number of 2x2 km squares sampled was `r length(unique(localityYear$karta))` and `r length(unique(localityYear$sampleUnit))` sampling units and according to unique coordinates `r length(unique(paste0(localityYear$rt90_o, ";", localityYear$rt90_n)))`). It were counted a total number of visits of `r nrow(localityYear)` (year, square, unit). . **In that way, there are units or big squares that werent visited all the years**.


### Species data

```{r}
Y <- occurrSppCoord |> 
  select(karta, punkt, yr, latin, count) |>
  pivot_wider(id_cols = c(karta, punkt, yr), names_from = latin, values_from = count,
              values_fn = sum, values_fill = 0) |> 
  select(-yr, -punkt, -karta) |> 
  as.data.frame()

Y <- Y[, order(colnames(Y))]

```

```{r}
P <-  colMeans(Y > 0)
range(P) |> round(4)
hist(P, xlab = "Species prevalence (P)",xlim=c(0,1))
```

Most species exhibit low prevalence, clustering towards the rare end of the spectrum, while a few species show a significantly higher prevalence, indicating they are common across the sampled areas, even an species is occurring in the `r max(P)` of sites (`r names(which(P == max(P)))`).

### Covariates

#### Forest

"Three national maps containing information about Sweden’s woodlands and forests are already available. These maps include data collected in 2000, 2005 and 2010, each with cells of 25 x 25 metres. Up until 2010, the maps were based solely on satellite images from Landsat and SPOT. The 2015 SLU Forest Map contains a number of raster maps created by co-processing field inventories from Sweden’s National Forest Inventory (SLU), surface models from the Land Survey’s stereo-matched aerial photographs, and satellite images from Sentinel-2. The 2015 expansion of the SLU Forest Map was limited to areas where high-resolution images were available." SLU Web

![Coverage of national forest maps by year](images/coverage_SLU.png)

```{r}
lsuZips <- list.files("data/covariates/slu_forest/", pattern = ".zip", recursive = T, full.names = T)
lsuZipsSplit <- str_split(lsuZips, pattern = "/", simplify = T)

lsuList <- list()

run <- F

if(run){
  
  for(i in 1:length(lsuZips)){
    # i <- 4
    files_in_zip <- unzip(lsuZips[i], list = TRUE)$Name
    zip_tif <- grep("*_P_.*\\.tif$", files_in_zip, value = T)
    
    lsutmp <- list()
    
    for(a in 1:length(zip_tif)){
      # a  <- 2
      r <- rast(paste0("/vsizip/", lsuZips[i], "/", zip_tif)[a])
      
      # # Create a new temp raster
      r2 <- r
      
      #rescale temp raster to new resolution
      res(r2) <- 100 
      # 
      # Resample the raster to 100m x 100m using mean aggregation
      r_resampled <- resample(r, r2, method = "average")
      
      lsutmp[[a]] <- coordSampleUnits |> 
        st_transform(crs=crs(r)) |> 
        terra::extract(x = r_resampled) |> 
        select(all_of(names(r)))
    }
    
    lsuList[[i]] <- bind_cols(lsutmp)
    
  }
  
  save(lsuList, file = file.path("data", "covariates", "slu_forest", "extracted_data.RData"))
}else{
  load(file = file.path("data", "covariates", "slu_forest", "extracted_data_100m.RData"))
}

names(lsuList) <- years
```


```{r}
get_forest_info <- function(locality.df, forest.list, years) {
  result <- list()
  for (i in 1:length(years)) {
    year_i <- as.character(years[i])
    index <- which(locality.df$yr == year_i)
    if (year_i %in% names(forest.list)) {
      info_i <- forest.list[[year_i]]
      colnames(info_i) <- sub(pattern = "_[0-9]{2}", replacement = "", colnames(info_i) )
      df <- info_i[index, ] |> 
        mutate(index = index, yr = year_i)
      result[[i]] <- df
    }
  }
  result <- bind_rows(result)
  result <- result[order(result$index), ] |>
    relocate(index, yr, last_col())
  
  return(result)
}

forestRaw <- get_forest_info(locality.df = localityYear, forest.list = lsuList, years = years) |> 
  filter(yr != 2015) |> ########## Watchout!!!!!!!!!!!!
  select(-DIAMETER_XX_P, -BASALAREA_XX_P, ) |> 
  filter(if_any(-c(index, yr), ~ !is.na(.))) 

forestRaw[is.na(forestRaw) ] <- 0 ########## Watchout!!!!!!!!!!!!

table(forestRaw$yr)

```


```{r}
forestRaw_long <- forestRaw |> 
  select(-c(index, yr)) |> 
  pivot_longer(cols = c(1:11))

# Calculate NA and zero counts per variable
na_zero_summary <- forestRaw_long |> 
  group_by(name) |> 
  summarise(
    n_na = sum(is.na(value)),
    n_zero = sum(value == 0, na.rm = TRUE), # na.rm = TRUE to ignore NA in the comparison
    total_n = n()
  ) |> 
  mutate(
    label = paste0("NA: ", n_na, "\nZero: ", n_zero)
  )

ggplot(forestRaw_long, aes(value)) +
  geom_density() +
  facet_wrap(~name, scales = "free") +
  geom_text(data = na_zero_summary,
            aes(x = Inf, y = Inf, label = label),
            hjust = 1.1, vjust = 1.1, size = 3)
```

```{r}
# transforming forest info

forestInfo <- forestRaw

forestInfo$BEECHVOL_XX_P <- (forestInfo$BEECHVOL_XX_P > 0) * 1
forestInfo$BIRCHVOL_XX_P <- (forestInfo$BIRCHVOL_XX_P > 0) * 1
forestInfo$CONTORTAVOL_XX_P <- (forestInfo$CONTORTAVOL_XX_P > 0) * 1
forestInfo$DECIDUOUSVOL_XX_P <- (forestInfo$DECIDUOUSVOL_XX_P > 0) * 1
forestInfo$OAKVOL_XX_P <- (forestInfo$OAKVOL_XX_P > 0) * 1
forestInfo$PINEVOL_XX_P <- (forestInfo$PINEVOL_XX_P > 0) * 1
forestInfo$SPRUCEVOL_XX_P <- (forestInfo$SPRUCEVOL_XX_P > 0) * 1
```


```{r}
forestInfo_long <- forestInfo |> 
  select(-c(index, yr)) |> 
  pivot_longer(cols = c(1:11))

# Calculate NA and zero counts per variable
na_zero_summary <- forestInfo_long |> 
  group_by(name) |> 
  summarise(
    n_na = sum(is.na(value)),
    n_zero = sum(value == 0, na.rm = TRUE), # na.rm = TRUE to ignore NA in the comparison
    total_n = n()
  ) |> 
  mutate(
    label = paste0("NA: ", n_na, "\nZero: ", n_zero)
  )

ggplot(forestInfo_long, aes(value)) +
  geom_density() +
  facet_wrap(~name, scales = "free") +
  geom_text(data = na_zero_summary,
            aes(x = Inf, y = Inf, label = label),
            hjust = 1.1, vjust = 1.1, size = 3)
```


```{r}
#------------------------------- # just for proof of concept, I need to investigate why there are data without information even the other variables get me info
forestData <- forestInfo$index

Y <- Y[forestData, ]
localityYear <- localityYear[forestData, ] 
coordSampleUnits <- coordSampleUnits[forestData, ]

```

### LandUse

```{r}
library(terra)
clc <- rast("data/covariates/NMD/18/nmd2018bas_ogeneraliserad_v1_1.tif")
coltab(clc) <- NULL
clc2 <- clc
res(clc2) <- 100 
clc_resampled <- resample(clc, clc2, method = "near")

clcRaw <- coordSampleUnits |> 
  st_transform(crs=crs(clc)) |> 
  terra::extract(x = clc_resampled) |> 
  select(-ID) |> 
  mutate(Klass = iconv(Klass, from = "ISO-8859-1", to = "UTF-8"))
  
clcInfo <- clcRaw |> 
  mutate(
    Klass = case_when(
      Klass %in% c("Exploaterad mark, väg/järnväg", "Åkermark", "Exploaterad mark, 
                        byggnad", "Exploaterad mark, ej byggnad eller väg/järnväg") ~ "Urb",
      Klass %in% c("Triviallövskog (utanför våtmark)", "Triviallövskog med ädellövinslag (utanför våtmark)", 
                        "Lövblandad barrskog (utanför våtmark)", "Ädellövskog (utanför våtmark)",
                        "Lövblandad barrskog (på våtmark)", "Ädellövskog (på våtmark)", 
                        "Triviallövskog (på våtmark)", "Triviallövskog med ädellövinslag (på våtmark)") ~ "Br",
      Klass %in% c("Granskog (utanför våtmark)", "Tallskog (utanför våtmark)", 
                        "Barrblandskog (utanför våtmark)", "Tallskog (på våtmark)", 
                        "Granskog (på våtmark)", "Barrblandskog (på våtmark)") ~ "Co",
      Klass %in% c("Övrig öppen mark med vegetation", "Övrig öppen mark utan vegetation") ~ "Op",
      Klass == "Hav" ~ "Ma",
      Klass %in% c("Sjö och vattendrag", "Öppen våtmark", "Temporärt ej skog (på våtmark)", 
                        "Temporärt ej skog (utanför våtmark)") ~ "We",
      Klass == "" ~ "", # Keep the empty string as is
      TRUE ~ NA_character_  # For any other value (shouldn't happen if your data is clean)
    )
  )

#------------------------------- # just for proof of concept, I need to investigate why there are sea data/NA
clcData <- which(clcInfo$Klass != "" & !is.na(clcInfo$Klass))

clcInfo <- clcInfo[clcData, , drop = F]
Y <- Y[clcData, ]
localityYear <- localityYear[clcData, ] 
coordSampleUnits <- coordSampleUnits[clcData, ]
forestInfo <- forestInfo[clcData, ]

```
### Climate

Keep stable or vary between years (?). My main concern is about "land" use.

```{r}
#| warning: false

worldClim <- rast(c("data/covariates/wc2.1_30s_bio/wc2.1_30s_bio_5.tif",
               "data/covariates/wc2.1_30s_bio/wc2.1_30s_bio_18.tif"))
  
clim <- coordSampleUnits |> 
  st_transform(crs=crs(worldClim)) |> 
  terra::extract(x = worldClim) |> 
  select(-ID)

#------------------------------- # just for proof of concept, I need to investigate why there are sea data/NA
no_seaData <- which((!is.na(clim$wc2.1_30s_bio_5)))

Y <- Y[no_seaData, ]
localityYear <- localityYear[no_seaData, ] 
coordSampleUnits <- coordSampleUnits[no_seaData, ]
clim <- clim[no_seaData, ]
forestInfo <- forestInfo[no_seaData, ]
clcInfo <- clcInfo[no_seaData, , drop = F]
#-----------------------------

XData <- forestInfo |> 
  select(-c(index, yr)) |> 
  bind_cols(clim, clcInfo) |> 
  as.data.frame() |> 
  mutate(Klass = as.factor(Klass))

row.names(XData) <- paste0(localityYear$karta, ":", localityYear$yr, ":", localityYear$punkt)

```

```{r}
zero_spp <-  which(colSums(Y) == 0)

Y <- Y[ , -zero_spp]
```

```{r}

## Heureka inputs

heureka <- T

if(heureka){
  forestRaw |>
    rename_with(~ paste0(., "_raw")) |> 
    slice(clcData) |>    
    slice(no_seaData) |> 
    bind_cols(XData) |> 
    write.csv("slu/input_heureka_forest.csv", row.names = F)
  
  coordSampleUnits |> 
    st_transform("EPSG:3006") |> 
    mutate(longSweref99 = sf::st_coordinates(.)[,1], latSweref99 = sf::st_coordinates(.)[,2]) |> 
    st_transform("EPSG:4326") |> 
    mutate(longWGS = sf::st_coordinates(.)[,1], latWGS = sf::st_coordinates(.)[,2]) |>
    st_drop_geometry() |> 
    write.csv("slu/input_heureka_coordSampleUnits.csv", row.names = F)
}




```


### Phylogenetic

First, we have to resolve names used in the phylogeny database and the bird survey.(BirdTree database)\[https://birdtree.org/\] The database come froms: (Jetz, W., G. H. Thomas, J. B. Joy, K. Hartmann, and A. O. Mooers. 2012. The global diversity of birds in space and time. Nature 491:444-448)\[https://www-nature-com.ludwig.lub.lu.se/articles/nature11631\]. There is no API, so write and retrieve manually. The species list from the database were web scrapping.

```{r}

birdTreeSpp <- read.csv("data/bird_tree/birdTree_spp.csv")
sppY <- colnames(Y)

sppResolved <- data.frame("scientificName" = NA, "bird_tree" = NA)

run <- F

if(run){

  for(i in 1:length(sppY)){
    spp.i <- sppY[i]
    
    isMissingSppTree <- !(spp.i %in% birdTreeSpp$species)
      
    if(isMissingSppTree){
        
      if(spp.i == "Corvus cornix"){
        
        synSppY.i <- "Corvus corone"
          
        }else if(spp.i == "Loxia bifasciata"){
          synSppY.i <- "Loxia leucoptera"
    
        }else if(spp.i == "Curruca cantillans"){
          synSppY.i <- "Sylvia cantillans"
    
        }else if(spp.i == "Columba livia f. domestica"){
          synSppY.i <- "Columba livia"
          
        }else{
          
        synSppY.i <- synonyms(spp.i, db = "nbn", rec_only = T, accepted = F, rank = "species", ask = F) |> 
          map_df(~ .x)
        
        if(ncol(synSppY.i) == 1 | ncol(synSppY.i) == 0){
          synSppY.i <- NA
        }else{
          synSppY.i <-  synSppY.i |> 
            select(nameString) |> 
            pull()
          synSppY.i <- (synSppY.i[synSppY.i %in% birdTreeSpp$species]) |> 
            unique()
        }
    
        }
      }else{
        synSppY.i <- spp.i
      }
     sppResolved[i,"scientificName"] <- spp.i
     sppResolved[i,"bird_tree"] <- synSppY.i
  }
  
  write.csv(sppResolved, "data/bird_tree/taxonomical_synonyms_birdtree.csv", row.names = F)
}else{
  
  sppResolved <- read.csv("data/bird_tree/taxonomical_synonyms_birdtree.csv")

}


# tree-pruner-79dc275b-d443-43a0-ad48-65f64e969c4f # 1000
# tree-pruner-cc685151-9887-452d-9dc0-01386d287412 # 100 removing NA data

Trees <- ape::read.nexus("data/bird_tree/n100_naRemoved/output.nex")

## MISSING. Consensus method (?)


phyloTree <- Trees[[sample(1:100, 1)]]


phyloTree$tip.label <- phyloTree$tip.label |> 
  str_replace(pattern = "_", " ")

#----------------
# remove spp
# phyloTree <- drop.tip(phyloTree, c("Anser_indicus", "Falco_vespertinus"))

#----------------

phyloTree$tip.label <- sppResolved$scientificName[match(phyloTree$tip.label, sppResolved$bird_tree)]

```

### Traits

```{r}
tr1 <- read.xlsx("data/traits/AVONET/TraitData/AVONET3_BirdTree.xlsx", sheet = 2) |> 
  rename(bird_tree = Species3) |>
  right_join(sppResolved, by = "bird_tree" ) |>  
  select(scientificName, Mass, Habitat, Habitat.Density, Trophic.Niche, Primary.Lifestyle, Migration)
 
TrData <- tr1 |>  
  as.data.frame()

row.names(TrData) <- TrData$scientificName 
 
TrData <- select(TrData, -scientificName)

TrData <- TrData[order(row.names(TrData)), ]

```

## Set up the model

### Study desing

```{r}
studyDesign <- localityYear |> 
  select(karta, yr, sampleUnit) |> 
  mutate(across(everything(), as.factor)) |> 
  as.data.frame()

row.names(studyDesign) <- paste0(studyDesign$karta, ":", studyDesign$yr, ":" ,studyDesign$sampleUnit)

xy <- coordSampleUnits |> 
  select(-c(yr, punkt, sampleUnit)) |> 
  st_transform("EPSG:4326")|>  
    mutate(
    long = sf::st_coordinates(.)[,1],
    lat = sf::st_coordinates(.)[,2]
  ) |> 
  st_drop_geometry() |> 
  distinct() |> 
  as.data.frame()

le <-  levels(studyDesign$karta)
xy.karta <-  matrix(nrow=length(le), ncol=2)  
rownames(xy.karta) <-  le

for(i in 1:length(le)){
  xy.cle <- xy[which(xy$karta == le[i]), c("long", "lat")]
  xy.karta[le[i],] <- colMeans(xy.cle)
}

colnames(xy.karta) <-  c("long", "lat")

write.csv(xy.karta, "xy.karta.csv", row.names = T)

```

### Random effects

```{r}

rL.sampleUnit <- HmscRandomLevel(units = levels(studyDesign$sampleUnit))
rL.year <- HmscRandomLevel(units = levels(studyDesign$yr))

```

Clean Environment

```{r}
toKeep <- c("model", "modeltype","XData", "XFormula", "TrData", "TrFormula", "phyloTree", "Y", "rL.sampleUnit", "rL.locality", "rL.year", "studyDesign",
            "sampleUnits", "transform_Y_to_abunCpres", "xy.karta")
rm(list = setdiff(ls(), toKeep))
gc()

```

```{r}

colnames(XData)

XFormula <- ~ Klass + AGE_XX_P + BEECHVOL_XX_P + CONTORTAVOL_XX_P + BIRCHVOL_XX_P + DECIDUOUSVOL_XX_P + HEIGHT_XX_P + OAKVOL_XX_P + PINEVOL_XX_P + SPRUCEVOL_XX_P + TOTALVOL_XX_P + BIOMASS_XX_P + poly(wc2.1_30s_bio_5, degree = 2) + poly(wc2.1_30s_bio_18, degree = 2)


```


```{r}
TrFormula <- ~ log(Mass) + Habitat +  Trophic.Niche + Habitat.Density + Primary.Lifestyle + Migration

```

### Define model

#### Three random levels and full gausian process


```{r}
rL.locality <-  HmscRandomLevel(sData = xy.karta, longlat = TRUE)
```


```{r}
m.abu = Hmsc(Y = Y,
 XData = XData, XFormula = XFormula,
 TrData = TrData, TrFormula = TrFormula,
 phyloTree = phyloTree,
 distr = "lognormal poisson", 
 studyDesign = studyDesign, ranLevels = list("karta" = rL.locality, "yr" = rL.year, "sampleUnit" = rL.sampleUnit)
 )

m.abuCpres = Hmsc(Y = transform_Y_to_abunCpres(Y),
 XData = XData, XFormula = XFormula,
 TrData = TrData, TrFormula = TrFormula,
 phyloTree = phyloTree,
 distr = "lognormal poisson", 
 studyDesign = studyDesign, ranLevels = list("karta" = rL.locality, "yr" = rL.year, "sampleUnit" = rL.sampleUnit)
 )

m.pa = Hmsc(Y = 1*(Y>0),
 XData = XData, XFormula = XFormula,
 TrData = TrData, TrFormula = TrFormula,
 phyloTree = phyloTree,
 distr = "probit", 
 studyDesign = studyDesign, ranLevels = list("karta" = rL.locality, "yr" = rL.year, "sampleUnit" = rL.sampleUnit)
 )
```


```{r}
model <- "sbsF_full"
modeltype <- c("abu", "aCp", "pa")

dir.create("models", showWarnings = F)
models <-  list(m.abu, m.abuCpres, m.pa )
names(models) <- paste0(model, "_", modeltype)
save(models, file = file.path("models", "unfitted_models_full.RData"))
```

#### To make the process faster: spatial level and temporal level only and NNGP in GPU proccessing

```{r}
rL.locality <-  HmscRandomLevel(sData = xy.karta, longlat = TRUE, sMethod = 'NNGP', nNeighbours = 8)
```


```{r}
m.abu = Hmsc(Y = Y,
 XData = XData, XFormula = XFormula,
 TrData = TrData, TrFormula = TrFormula,
 phyloTree = phyloTree,
 distr = "lognormal poisson",
 studyDesign = studyDesign,
 ranLevels = list("karta" = rL.locality, "yr" = rL.year)
 )

m.abuCpres = Hmsc(Y = transform_Y_to_abunCpres(Y),
 XData = XData, XFormula = XFormula,
 TrData = TrData, TrFormula = TrFormula,
 phyloTree = phyloTree,
 distr = "lognormal poisson", 
 studyDesign = studyDesign, 
 ranLevels = list("karta" = rL.locality, "yr" = rL.year)
 )

m.pa = Hmsc(Y = 1*(Y>0),
 XData = XData, XFormula = XFormula,
 TrData = TrData, TrFormula = TrFormula,
 phyloTree = phyloTree,
 distr = "probit", 
 studyDesign = studyDesign, 
 ranLevels = list("karta" = rL.locality, "yr" = rL.year)
 )
```


```{r}
model <- "sbsF_ngpp_2rl"
modeltype <- c("abu", "aCp", "pa")

dir.create("models", showWarnings = F)
models <-  list(m.abu, m.abuCpres, m.pa)
names(models) <- paste0(model, "_", modeltype)
save(models, file = file.path("models", "unfitted_models_NGPP.RData"))
```

#### Three random levels: spatial, samling unit, and temporal level and NNGP in GPU proccessing

```{r}
rL.locality <-  HmscRandomLevel(sData = xy.karta, longlat = TRUE, sMethod = 'NNGP', nNeighbours = 8)
```


```{r}
m.abu = Hmsc(Y = Y,
 XData = XData, XFormula = XFormula,
 TrData = TrData, TrFormula = TrFormula,
 phyloTree = phyloTree,
 distr = "lognormal poisson", 
 studyDesign = studyDesign, ranLevels = list("karta" = rL.locality, "yr" = rL.year, "sampleUnit" = rL.sampleUnit)
 )

m.abuCpres = Hmsc(Y = transform_Y_to_abunCpres(Y),
 XData = XData, XFormula = XFormula,
 TrData = TrData, TrFormula = TrFormula,
 phyloTree = phyloTree,
 distr = "lognormal poisson", 
 studyDesign = studyDesign, ranLevels = list("karta" = rL.locality, "yr" = rL.year, "sampleUnit" = rL.sampleUnit)
 )

m.pa = Hmsc(Y = 1*(Y>0),
 XData = XData, XFormula = XFormula,
 TrData = TrData, TrFormula = TrFormula,
 phyloTree = phyloTree,
 distr = "probit", 
 studyDesign = studyDesign, ranLevels = list("karta" = rL.locality, "yr" = rL.year, "sampleUnit" = rL.sampleUnit)
 )


m.abu$call

```

```{r}
model <- "sbsF_ngpp_3rl"
modeltype <- c("abu", "aCp", "pa")

dir.create("models", showWarnings = F)
models <-  list(m.abu, m.abuCpres, m.pa)
names(models) <- paste0(model, "_", modeltype)
save(models, file = file.path("models", "unfitted_models_NGPP_3rl.RData"))
```


```{r}
sampleMcmc(m.abu, samples=2)
```

```{r}
# Yx <- Y |> 
#   pivot_longer(
#     cols = everything(), # Pivotear todas las columnas excepto "id"
#     names_to = "especie",
#     values_to = "abundancia"
#   ) |> 
#   filter(abundancia != 0) |> 
```

