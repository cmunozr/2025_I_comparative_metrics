---
title: "Quantitative biodiversity modelling for finance and companies"
subtitle: "Project 1: compare metrics"
author: 
  - name: "Carlos Muñoz"
    email: carlos_jair.munoz@cec.lu.se
    affiliations: 
      - ref: CEC

affiliations:
  - id: CEC
    name: Centre for Environmental and Climate Science, Lund University
    department: Centre for Environmental and Climate Science 
    address: Kontaktvägen 10
    city: Lund
    postal-code: 22362
    url: https://www.cec.lu.se/home
   
format:
  html:
    theme: cosmo # try other themes from https://quarto.org/docs/output-formats/html-themes.html
    toc: true # this will enable Table of Contents
    code-fold: false #try changing it and see what happens
    embed-resources: true # this is so your file would embed all images. 
    output-dir: "../quarto_reports/"  
  pdf: default
  docx: default

execute: 
  echo: true    #use to show/hide R-code in the report
  cache: false
number-sections: true #sectioner can be automatically numbered
title-block-banner: true
---

## Introduction

### General framework

-   Biodiversity is declining at an alarming rate, faster than ever in human history (Barnosky et al., 2011; Ceballos et al., 2015).
-   Economic activity is at the core of the biodiversity crisis, but biodiversity loss also represents a significant physical threat, reputational and regulatory risk to business and financial activities.
-   BIOPATH (Sweden) seeks to develop innovative approaches to integrate biodiversity considerations into financial and business decision-making to halt and reverse biodiversity loss.

### Biodiversity metrics

-   Biodiversity databases are the foundation for effective management strategies, but data alone isn't enough to stop biodiversity loss. We need to turn this data into useful information. This means using some way of biodiversity measurement to move activities from harming nature to being neutral or even positive.
-   Burgess and colleagues (2024) identified 573 metrics developed to inform decision-making related to biodiversity.
-   What metrics should be used?

#### A Tension

-   Business Perspective: Need for accessible, cost-effective and standardized. Importance of simplicity.
-   Natural scientific Perspective:Reflect ecological complexity.Capture multiple dimensions.
-   Maybe a set instead of only one silver bullet

### Challenge

-   The heart of the matter with biodiversity state metrics is how biodiversity change is interpreted and, consequently, how choices are made may be significantly impacted by the selection and response of biodiversity measures (Silvestro et al., 2023). It is critical to understand how different measures respond to changes, which metrics are particularly sensitive to early signals of biodiversity loss, and which metrics respond to changes consistently.
-   How transparently, efficiently, and credibly these measures capture the state and changes on multiple dimensions of biodiversity?

## Objective

To compare biodiversity metrics using quantitative models to assess how accurately they reflect biodiversity states and trends in different biodiversity change scenarios.

-   Birds as focal study taxon
-   Biodiversity change because change of habitat: forestry management scenarios

**THERE IS A NOTORIOUS GAP ABOUT WHY TO USE BIRDS AND WHY FOREST**

## Rol of Hmsc

An Hmsc model provides predictions at the species-community level. This enables the spatial representation of biodiversity to analyse and evaluate biodiversity metrics’ performance and variation through environmental and spatial gradients while counting for uncertainties.

## Setup

```{r, setup}
knitr::opts_knit$set(root.dir = "c:/Users/Carlos Munoz/Documents/Ph.D/6_courses/2025_I_comparative_metrics/")
```

```{r}
#| message: false
#| warning: false

library(Hmsc)
library(tidyverse)
library(data.table)
library(terra)
library(sf)
library(maps)
library(ape)
library(taxize)
library(remotes)
library(phytools)
library(openxlsx)
library(tidyterra)
library(viridis)
library(lwgeom)
library(ggrepel)
library(gt)
```

```{r}
options("GDAL_DATA" = Sys.getenv("GDAL_DATA")) # Ensure GDAL_DATA is set if needed
options("OSR_USE_NON_DEPRECATED" = "NO")
```


```{r}
transform_Y_to_abunCpres <- function(data) {
  data |> mutate(across(everything(), ~ ifelse(. == 0, NA, scale(log(.)))))
}
```


```{r}
set.seed(11072024)
```

## Breeding Finish Bird Survey


```{r}
# coordinates 
coords <- st_read("data/fbs/vakiolinja/Vakiolinjat_routes.geojson")

# routes (names and dates)
routes <- read.csv("data/fbs/vakiolinja/vakiolinja1_20250626.csv")

# occurrences by route (spp key, and counts in points and lines)

occurr_route <- read.csv("data/fbs/vakiolinja/vakiolinja2_20250626.csv") 

# occurrences by section route (spp key, and counts in points and lines)

occurr_sect_route <- read.csv("data/fbs/vakiolinja/vakiolinja3_20250626.csv") 


```

```{r} 
# late Spring/Summer routes from 2009-2021 (years because the MS-NFI)

routes <- routes |> 
  mutate(out_date = ifelse((month < 5 | month > 7 | year < 2009 | year > 2021), 1, 0 ))

event_ids_to_match <- routes |> 
  filter(out_date == 1) |> 
  pull(eventId) |> 
  unique()

occurr_route <- occurr_route |> 
  mutate(out_date = as.numeric(eventId %in% event_ids_to_match))

occurr_sect_route <- occurr_sect_route |> 
  mutate(out_date = as.numeric(eventId %in% event_ids_to_match))

# are there routes that we have to remove because no data?
routes |> 
  group_by(vakio) |> 
  summarise(total_events = n(), out_count = sum(out_date == 1)) |> 
  mutate(vakio_out = as.numeric(total_events == out_count)) |> 
  filter(vakio_out == 1)
  ##  No need to filter coords
  
# Filtering routes and routes

routes <- routes |> 
  filter(out_date != 1)

occurr_route <- occurr_route |> 
  filter(out_date != 1)

occurr_sect_route <- occurr_sect_route |> 
  filter(out_date != 1)


```

Species information in the FBS routes. There is no taxonomic data, so it needs to be retrieved from external data sets (using the GBIF and the Integrated Taxonomic Information System, ITIS as backup)

```{r}

spp_unique <- unique(occurr_sect_route$scientificName) |> sort()

run <-  F

if(run == T){
  tax_raw <- taxize::classification(spp_unique, db = "gbif")
  missing_index <- which(is.na(tax_raw))
  missing <- spp_unique[missing_index]
  tax_raw <- tax_raw[-missing_index]
  missing_tax <- taxize::classification(missing, db = "itis")
  tax_raw <- c(tax_raw, missing_tax)
  saveRDS(object = tax_raw, file = "data/fbs/tax_raw_data.rds")
}else{
  tax_raw <- readRDS(file = "data/fbs/tax_raw_data.rds")
}

tax_list <- list()

for (current_name in names(tax_raw)) {
  
  current_data <- tax_raw[[current_name]]
  
  if (!is.null(current_data)) {
    current_df <- as.data.frame(current_data)
    n.r <- nrow(current_df)
    cols <- current_df$rank
    high_rank <- cols[n.r]
    
    info <- as.list(current_df$name)
    names(info) <- cols
    info <- as.data.frame(info)
    
    info$id <- as.integer(current_df$id[n.r])
    info$input_name <- current_name 
    info$high_rank <- high_rank
    
    tax_list[[current_name]] <- info
  }
}

cols <- c("subkingdom", "infrakingdom", "subphylum", "infraphylum", "superclass",
          "subclass", "infraclass", "suborder", "superfamily")

tax <- list_rbind(tax_list) |> 
  relocate(subfamily, .after = family) |> 
  relocate(subspecies, .after = species) |> 
  select(-any_of(cols))

index_odo <- which(tax$subfamily == "Odocoileinae")
tax$kingdom[index_odo] <- "Animalia"
tax$phylum[index_odo] <- "Chordata"
tax$class[index_odo] <- "Mammalia"
tax$order[index_odo] <- "Artiodactila"
tax$family[index_odo] <- "Cervidae"
```


```{r}
# What classes do we have?
class_data <- tax |>
  count(class, name = "n")  |> 
  mutate(
    value = n / sum(n),
    csum = rev(cumsum(rev(value))),
    pos = value / 2 + lead(csum, 1),
    pos = if_else(is.na(pos), value / 2, pos),
    label = paste0(class, "\n", scales::percent(value))
  )

ggplot(class_data, aes(x = "", y = value, fill = fct_inorder(class))) +
  geom_col(width = 1, color = "white", linewidth = 0.5) +
  coord_polar(theta = "y") +
  labs(title = "Distribution of Taxonomic Labels by Class", fill = "Class") +
  theme_void() +
  geom_label_repel(aes(y = pos, label = label),
                   size = 3.5,
                   nudge_x = 1,
                   show.legend = FALSE,
                   force = 1,
                   max.overlaps = Inf,
                   box.padding = 0.5,
                   point.padding = 0.5
                   ) +
  guides(fill = guide_legend(title = "Class")) +
  theme(plot.title = element_text(hjust = 0.5, size = 14, face = "bold"))
```


```{r}
# Which is the distribution of birds in the data set? (using order)
aves_order_data_barplot <- tax |>
  filter(class == 'Aves') |>
  count(order, name = 'n') |>
  mutate(percentage = n / sum(n)) |>
  arrange(desc(n))

ggplot(aves_order_data_barplot, aes(x = reorder(order, -n), y = n, fill = order)) +
  geom_col(color = 'black') +
  labs(title = 'Distribution of Taxonomic Labels by Order (Class: Aves)',
       x = 'Order',
       y = 'Count',
       fill = 'Order') +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(hjust = 0.5, size = 14, face = 'bold')) +
  geom_text(aes(label = n), vjust = -0.5, size = 3)
```


```{r}
# What kind of taxonomic labels do we have?
high_rank_data_barplot <- tax |>
  count(high_rank, name = 'n') |>
  mutate(percentage = n / sum(n)) |>
  arrange(desc(n))

ggplot(high_rank_data_barplot, aes(x = reorder(high_rank, -n), y = n, fill = high_rank)) +
  geom_col(color = 'black') +
  labs(title = 'Distribution of Taxonomic Labels by High Rank',
       x = 'High Rank',
       y = 'Count',
       fill = 'High Rank') +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(hjust = 0.5, size = 14, face = 'bold')) +
  geom_text(aes(label = n), vjust = -0.5, size = 3)
```


```{r}
## From those that aren't species, how many of them are birds?

tax |> 
  filter(high_rank != "species", high_rank != "subspecies") |> 
  count(class, high_rank, name = 'n') |> 
  gt()

#------

spp_tax_data <- tax |> 
  filter(high_rank == "species" | high_rank ==	"subspecies", class == "Aves")

```

We need to filter the route information data to actual places in which the selected species were observed. List from Bakx et al, 2023. So we need to ovelap the info from the list with the taxonomic data.

```{r}
species_list <- read.xlsx(xlsxFile = "data/ecs24559-sup-0001-appendixs1.xlsx", sheet = 1)

species_list <- species_list |> 
  mutate(in_route = species_list$Latin_name %in% spp_tax_data$input_name) 

species <- species_list |> 
  filter(in_route == T) |> 
  select(Latin_name) |> 
  pull()
```

From the pool of species we have `r length(species)` in the subset of FBS routes. We are missing the next:

```{r}
species_list |> 
  filter(in_route == F) |>
  gt()
```

Now the information routes need to be filtered to the species what we are looking for: 

```{r}
occurr_sect_route <- occurr_sect_route |> 
  filter(scientificName %in% species)

route_number_sppinfo <- occurr_sect_route$vakio |> 
  unique()
```

Now lets to explore the spatial information on valid eventids (inside season, years and selected species) with biotope information

```{r}
# exploring spatial information on valid eventids (inside season, years and selected species) with biotope information

occurr_sect_route <- occurr_sect_route |> 
  mutate(biotope_logic = ifelse(biotope == "", yes = 0, no = 1))

no_biotope <- occurr_sect_route |> 
  filter(biotope == "")
no_biotope_table <- (table(no_biotope$vakio, no_biotope$year) > 0) 

# a) what percentage of routes have no biotope information or subsection information
# b) of those without information how many times have been without biotope info?

no_biotope_routes <- no_biotope_table |> 
  rowSums()

## a 
length(no_biotope_routes)/length(route_number_sppinfo)*100

## b
table(no_biotope_routes)/length(route_number_sppinfo)*100

no_biotope_routes_df <- data.frame(
  vakio = names(no_biotope_routes),
  times_missing = no_biotope_routes
)

# how many routes have no had biotope or subsection info each year?
# what percentege of routes that were sample each year dont have biotope or subsection info?

no_biotope_years <- no_biotope_table |> 
  colSums()

sample_by_year <- occurr_sect_route |> 
  filter(year != 2019) |> 
  group_by(year) |> 
  summarize(sample_routes = length(unique(vakio)))

percent_sample_no_biotope <- no_biotope_years/sample_by_year$sample_routes*100

hist(percent_sample_no_biotope, 
     main = "Distribution of Annual Percentage of Routes with Missing Biotope Data",
     xlab = "Percentage of Routes with Missing Biotope Data (%)")
```


```{r}
# how many of the biotope and subsection information is missing? Is all the route?

occurr_sect_route |> 
  group_by(year, vakio) |> 
  # 'total_rows' is the total number of sections, 'count' is the number of sections missing biotope info
  summarise(total_rows = n(), count = sum(biotope == "")) |> 
  filter(count != 0) |> 
  mutate(vakio = as.factor(vakio)) |> 
  pivot_longer(cols = c(total_rows, count), names_to = "category", values_to = "rows") |> 
  ggplot(aes(x = vakio, y = rows, fill = category )) +
  geom_col(position="dodge") + 
  coord_flip() + 
  facet_wrap(vars(year), scales="free") +
  # Updated labels for better clarity
  labs(
    title = "Comparison of Total vs. Missing Biotope Sections for Affected Routes, by Year",
    x = "Number of Sections",
    y = "Route ID (vakio)",
    fill = "Category"
  ) +
  # This function renames the items in the legend
  scale_fill_discrete(
    labels = c(
      "count" = "Sections with Missing Biotope", 
      "total_rows" = "Total Sections"
    )
  )

```

```{r}
coords_nm <- str_split(coords$name, pattern = ", ", simplify = T) |> 
  as.data.frame()
names(coords_nm) <- c("vakio", "str1", "str2", "numer")

route_number_sppinfo <- coords_nm$vakio %in% route_number_sppinfo

coords <- bind_cols(coords, coords_nm) |> 
  left_join(y = no_biotope_routes_df, by = "vakio") |> 
  mutate(vakio = as.numeric(vakio), 
         times_missing = as.factor(ifelse(is.na(times_missing), 0, times_missing)),
         route_number_sppinfo = route_number_sppinfo) |> 
  arrange(vakio)

write_sf(coords, "data/fbs/coords.gpkg", delete_layer = T)

```

How the missing biotope routes are spread in the country? Is some are prone to have less data?

```{r}
fin <- st_as_sf(map(database = "world", regions = "finland", plot = FALSE, fill = TRUE))

lvls <- levels(coords$times_missing)
turbo_discrete_colors <- viridis_pal(option = "turbo")(n = length(lvls) - 1)
custom_colors <- c(
  "0" = "gray",
  setNames(turbo_discrete_colors, lvls[lvls != "0"])
)

coords |> 
  ggplot() +
  geom_sf(data = fin) +
  geom_sf(aes(color = times_missing)) +
  scale_color_manual(
    values = custom_colors, 
    name = "Number of Years Missing Data", 
    drop = FALSE
  ) +
  labs(
    title = "Frequency of Years with Missing Biotope Data per Survey Route",
    subtitle = "Routes with no missing data are shown in grey."
  ) +
  theme_minimal()

```
Is some route without no species information?

```{r}
coords |> 
  ggplot() +
  geom_sf(data = fin) +
  geom_sf(aes(color = route_number_sppinfo), size = 1.5, alpha = 0.8) +
  scale_color_manual(
    values = c("TRUE" = "gray", "FALSE" = "red"),
    labels = c("TRUE" = "Species Information", "FALSE" = "No Species Information"),
    name = "Data Availability"
  ) +
  labs(
    title = "Spatial Distribution of Finnish Bird Survey Routes",
    subtitle = "Highlighting routes with and without focal species data"
  ) +
  theme_minimal()
```


```{r}

table(coords$times_missing) |>
  as.data.frame() |>
  rename(
    `Times Missing` = Var1, 
    `Number of Routes` = Freq
  ) |>
  gt()

```

Less than 5% of the routes have problems of "no biotope". If we remove these routes and sections, how many species are we loossing? How many info of them?

```{r}

occurrence_data <-  table(scientificName = occurr_sect_route$scientificName, biotope_logic = occurr_sect_route$biotope_logic) |>
  as.data.frame() |>
  pivot_wider(id_cols = scientificName, names_from = biotope_logic, values_from = Freq) |>
  rename(no_biotope_occurrences = `0`, biotope_occurrences = `1`) |>
  mutate(total_occurrences = (no_biotope_occurrences + biotope_occurrences),
         percent_no_biotope_occurrences = round((no_biotope_occurrences / total_occurrences) * 100, 2))


paircount_data <- occurr_sect_route |>
  group_by(scientificName) |>
  summarise(total_pairCount = sum(pairCount, na.rm = TRUE), .groups = 'drop') |>
  pivot_wider(
    id_cols = scientificName,
    names_from = biotope_logic,
    values_from = total_pairCount,
    values_fill = 0 # Fill NA with 0 if a species/biotope_logic combination has no pairCount entries
  ) |>
  rename(
    no_biotope_pairCount = `0`,
    biotope_pairCount = `1`
  ) |> 
  mutate(
    total_pairCount = no_biotope_pairCount + biotope_pairCount,
    percent_no_biotope_pairCount = round((no_biotope_pairCount / total_pairCount) * 100, 2)
  )

combined_data <- occurrence_data |>
  left_join(paircount_data, by = "scientificName")

combined_data |> 
  arrange(desc(percent_no_biotope_pairCount)) |> 
  gt() |>
  tab_spanner("Pair Count", 
              columns= ends_with("pairCount")) |> 
  cols_label(
    no_biotope_occurrences = "No Biotope",
    biotope_occurrences = "Biotope",
    total_occurrences = "Total",
    percent_no_biotope_occurrences = "% No Biotope",
    no_biotope_pairCount = "No Biotope (PairCount)",
    biotope_pairCount = "Biotope (PairCount)",
    total_pairCount = "Total PairCount",
    percent_no_biotope_pairCount = "% No Biotope (PairCount)"
  ) |> 
  opt_stylize(style = 1, color="cyan")

```
```{r}
number_strip <- str_split(occurr_sect_route$biotopeStripId, pattern = "#", simplify = T) |> 
  as.data.frame()
names(number_strip) <- c("str1", "number")

occurr_sect_route <- occurr_sect_route |> mutate(number = as.numeric(number))

```


```{r}

coords <- coords |> 
  filter(route_number_sppinfo == TRUE)

years_to_process <- unique(occurr_sect_route$year) |> 
  sort()

output_paths <- data.frame("year" = years_to_process, "path" = NA)

for (y in 1:length(years_to_process)) {
  
  current_year <- years_to_process[y]
  
  #current_year <- 2009
  message(paste("--- Processing year:", current_year, "---"))
  
  split_route_list_year <- list()
  
  for (a in 1:nrow(coords)) {
    #a <- 127
    route_id <- coords$vakio[a]
    route_a <- coords |> 
      filter(vakio == route_id) |> 
      st_transform(crs = "EPSG:2393")
      
    biotope_route_a <- occurr_sect_route |> 
      filter(year == current_year, vakio == route_id) |> # Using the 'current_year' variable
      select(biotopeStripId, startMeters, endMeters, meters, biotope, biotopeSpecifier) |> 
      distinct() |> 
      mutate(
        r_startMeters = startMeters / as.numeric(st_length(route_a)), 
        r_endMeters = endMeters / as.numeric(st_length(route_a))
      )
      
    # Proceed only if there is biotope data for this route in this year
    # Also proceed only if there are more than one biotope, only one is flag to 
    # no biotope data
    if (nrow(biotope_route_a) > 1) {
      split_route_i <- list()
      for (r in 1:nrow(biotope_route_a)) {
        split_route_i[[r]] <- st_linesubstring(
          route_a, 
          from = biotope_route_a$r_startMeters[r], 
          to = biotope_route_a$r_endMeters[r]
        )
      }
      
      split_route_i <- do.call("rbind", split_route_i) |> 
        bind_cols(biotope_route_a) |> 
        mutate(geom_type = st_geometry_type(geometry))
      
      split_route_flat <- split_route_i|> 
        filter(geom_type == "LINESTRING") |> 
        st_buffer(dist = 150, endCapStyle = "FLAT", joinStyle = "BEVEL")
      
      split_route_point <- split_route_i|> 
        filter(geom_type == "POINT") |> 
        st_buffer(dist = 150)
        
      split_route_list_year[[a]] <- rbind(split_route_flat, split_route_point) |> 
        arrange(r_endMeters)
    }
  }
  
  if (length(split_route_list_year) > 0) {
    year_sf <- st_as_sf(do.call("rbind", split_route_list_year))
    output_filename <- paste0("data/fbs/route_sections_", current_year, ".gpkg")
    write_sf(year_sf, output_filename, delete_layer = TRUE)
    output_paths[y,"path"] <- output_filename
    message(paste("Saved file:", output_filename))
  } else {
    message(paste("No biotope data found for any route in year", current_year, ". Skipping."))
  }
}
```

We remove the routes without biotope data in an eture year. In case of the route 148 in the year 2009 there is no information. After this removing, did we lose species?


From `r min(years)`to `r max(years)` (`r max(years) - min(years)` years), the number of 2x2 km squares sampled was `r length(unique(localityYear$karta))` and `r length(unique(localityYear$sampleUnit))` sampling units and according to unique coordinates `r length(unique(paste0(localityYear$rt90_o, ";", localityYear$rt90_n)))`). It were counted a total number of visits of `r nrow(localityYear)` (year, square, unit). . **In that way, there are units or big squares that werent visited all the years**.


### Species data

```{r}
Y <- occurrSppCoord |> 
  select(karta, punkt, yr, latin, count) |>
  pivot_wider(id_cols = c(karta, punkt, yr), names_from = latin, values_from = count,
              values_fn = sum, values_fill = 0) |> 
  select(-yr, -punkt, -karta) |> 
  as.data.frame()

Y <- Y[, order(colnames(Y))]

```

```{r}
P <-  colMeans(Y > 0)
range(P) |> round(4)
hist(P, xlab = "Species prevalence (P)",xlim=c(0,1))
```

Most species exhibit low prevalence, clustering towards the rare end of the spectrum, while a few species show a significantly higher prevalence, indicating they are common across the sampled areas, even an species is occurring in the `r max(P)` of sites (`r names(which(P == max(P)))`).

### Covariates

#### Forest

"Three national maps containing information about Sweden’s woodlands and forests are already available. These maps include data collected in 2000, 2005 and 2010, each with cells of 25 x 25 metres. Up until 2010, the maps were based solely on satellite images from Landsat and SPOT. The 2015 SLU Forest Map contains a number of raster maps created by co-processing field inventories from Sweden’s National Forest Inventory (SLU), surface models from the Land Survey’s stereo-matched aerial photographs, and satellite images from Sentinel-2. The 2015 expansion of the SLU Forest Map was limited to areas where high-resolution images were available." SLU Web

![Coverage of national forest maps by year](images/coverage_SLU.png)

```{r}
lsuZips <- list.files("data/covariates/slu_forest/", pattern = ".zip", recursive = T, full.names = T)
lsuZipsSplit <- str_split(lsuZips, pattern = "/", simplify = T)

lsuList <- list()

run <- F

if(run){
  
  for(i in 1:length(lsuZips)){
    # i <- 4
    files_in_zip <- unzip(lsuZips[i], list = TRUE)$Name
    zip_tif <- grep("*_P_.*\\.tif$", files_in_zip, value = T)
    
    lsutmp <- list()
    
    for(a in 1:length(zip_tif)){
      # a  <- 2
      r <- rast(paste0("/vsizip/", lsuZips[i], "/", zip_tif)[a])
      
      # # Create a new temp raster
      r2 <- r
      
      #rescale temp raster to new resolution
      res(r2) <- 100 
      # 
      # Resample the raster to 100m x 100m using mean aggregation
      r_resampled <- resample(r, r2, method = "average")
      
      lsutmp[[a]] <- coordSampleUnits |> 
        st_transform(crs=crs(r)) |> 
        terra::extract(x = r_resampled) |> 
        select(all_of(names(r)))
    }
    
    lsuList[[i]] <- bind_cols(lsutmp)
    
  }
  
  save(lsuList, file = file.path("data", "covariates", "slu_forest", "extracted_data.RData"))
}else{
  load(file = file.path("data", "covariates", "slu_forest", "extracted_data_100m.RData"))
}

names(lsuList) <- years
```


```{r}
get_forest_info <- function(locality.df, forest.list, years) {
  result <- list()
  for (i in 1:length(years)) {
    year_i <- as.character(years[i])
    index <- which(locality.df$yr == year_i)
    if (year_i %in% names(forest.list)) {
      info_i <- forest.list[[year_i]]
      colnames(info_i) <- sub(pattern = "_[0-9]{2}", replacement = "", colnames(info_i) )
      df <- info_i[index, ] |> 
        mutate(index = index, yr = year_i)
      result[[i]] <- df
    }
  }
  result <- bind_rows(result)
  result <- result[order(result$index), ] |>
    relocate(index, yr, last_col())
  
  return(result)
}

forestRaw <- get_forest_info(locality.df = localityYear, forest.list = lsuList, years = years) |> 
  filter(yr != 2015) |> ########## Watchout!!!!!!!!!!!!
  select(-DIAMETER_XX_P, -BASALAREA_XX_P, ) |> 
  filter(if_any(-c(index, yr), ~ !is.na(.))) 

forestRaw[is.na(forestRaw) ] <- 0 ########## Watchout!!!!!!!!!!!!

table(forestRaw$yr)

```


```{r}
forestRaw_long <- forestRaw |> 
  select(-c(index, yr)) |> 
  pivot_longer(cols = c(1:11))

# Calculate NA and zero counts per variable
na_zero_summary <- forestRaw_long |> 
  group_by(name) |> 
  summarise(
    n_na = sum(is.na(value)),
    n_zero = sum(value == 0, na.rm = TRUE), # na.rm = TRUE to ignore NA in the comparison
    total_n = n()
  ) |> 
  mutate(
    label = paste0("NA: ", n_na, "\nZero: ", n_zero)
  )

ggplot(forestRaw_long, aes(value)) +
  geom_density() +
  facet_wrap(~name, scales = "free") +
  geom_text(data = na_zero_summary,
            aes(x = Inf, y = Inf, label = label),
            hjust = 1.1, vjust = 1.1, size = 3)
```

```{r}
# transforming forest info

forestInfo <- forestRaw

forestInfo$BEECHVOL_XX_P <- (forestInfo$BEECHVOL_XX_P > 0) * 1
forestInfo$BIRCHVOL_XX_P <- (forestInfo$BIRCHVOL_XX_P > 0) * 1
forestInfo$CONTORTAVOL_XX_P <- (forestInfo$CONTORTAVOL_XX_P > 0) * 1
forestInfo$DECIDUOUSVOL_XX_P <- (forestInfo$DECIDUOUSVOL_XX_P > 0) * 1
forestInfo$OAKVOL_XX_P <- (forestInfo$OAKVOL_XX_P > 0) * 1
forestInfo$PINEVOL_XX_P <- (forestInfo$PINEVOL_XX_P > 0) * 1
forestInfo$SPRUCEVOL_XX_P <- (forestInfo$SPRUCEVOL_XX_P > 0) * 1
```


```{r}
forestInfo_long <- forestInfo |> 
  select(-c(index, yr)) |> 
  pivot_longer(cols = c(1:11))

# Calculate NA and zero counts per variable
na_zero_summary <- forestInfo_long |> 
  group_by(name) |> 
  summarise(
    n_na = sum(is.na(value)),
    n_zero = sum(value == 0, na.rm = TRUE), # na.rm = TRUE to ignore NA in the comparison
    total_n = n()
  ) |> 
  mutate(
    label = paste0("NA: ", n_na, "\nZero: ", n_zero)
  )

ggplot(forestInfo_long, aes(value)) +
  geom_density() +
  facet_wrap(~name, scales = "free") +
  geom_text(data = na_zero_summary,
            aes(x = Inf, y = Inf, label = label),
            hjust = 1.1, vjust = 1.1, size = 3)
```


```{r}
#------------------------------- # just for proof of concept, I need to investigate why there are data without information even the other variables get me info
forestData <- forestInfo$index

Y <- Y[forestData, ]
localityYear <- localityYear[forestData, ] 
coordSampleUnits <- coordSampleUnits[forestData, ]

```

### LandUse

```{r}
library(terra)
clc <- rast("data/covariates/NMD/18/nmd2018bas_ogeneraliserad_v1_1.tif")
coltab(clc) <- NULL
clc2 <- clc
res(clc2) <- 100 
clc_resampled <- resample(clc, clc2, method = "near")

clcRaw <- coordSampleUnits |> 
  st_transform(crs=crs(clc)) |> 
  terra::extract(x = clc_resampled) |> 
  select(-ID) |> 
  mutate(Klass = iconv(Klass, from = "ISO-8859-1", to = "UTF-8"))
  
clcInfo <- clcRaw |> 
  mutate(
    Klass = case_when(
      Klass %in% c("Exploaterad mark, väg/järnväg", "Åkermark", "Exploaterad mark, 
                        byggnad", "Exploaterad mark, ej byggnad eller väg/järnväg") ~ "Urb",
      Klass %in% c("Triviallövskog (utanför våtmark)", "Triviallövskog med ädellövinslag (utanför våtmark)", 
                        "Lövblandad barrskog (utanför våtmark)", "Ädellövskog (utanför våtmark)",
                        "Lövblandad barrskog (på våtmark)", "Ädellövskog (på våtmark)", 
                        "Triviallövskog (på våtmark)", "Triviallövskog med ädellövinslag (på våtmark)") ~ "Br",
      Klass %in% c("Granskog (utanför våtmark)", "Tallskog (utanför våtmark)", 
                        "Barrblandskog (utanför våtmark)", "Tallskog (på våtmark)", 
                        "Granskog (på våtmark)", "Barrblandskog (på våtmark)") ~ "Co",
      Klass %in% c("Övrig öppen mark med vegetation", "Övrig öppen mark utan vegetation") ~ "Op",
      Klass == "Hav" ~ "Ma",
      Klass %in% c("Sjö och vattendrag", "Öppen våtmark", "Temporärt ej skog (på våtmark)", 
                        "Temporärt ej skog (utanför våtmark)") ~ "We",
      Klass == "" ~ "", # Keep the empty string as is
      TRUE ~ NA_character_  # For any other value (shouldn't happen if your data is clean)
    )
  )

#------------------------------- # just for proof of concept, I need to investigate why there are sea data/NA
clcData <- which(clcInfo$Klass != "" & !is.na(clcInfo$Klass))

clcInfo <- clcInfo[clcData, , drop = F]
Y <- Y[clcData, ]
localityYear <- localityYear[clcData, ] 
coordSampleUnits <- coordSampleUnits[clcData, ]
forestInfo <- forestInfo[clcData, ]

```
### Climate

Keep stable or vary between years (?). My main concern is about "land" use.

```{r}
#| warning: false

worldClim <- rast(c("data/covariates/wc2.1_30s_bio/wc2.1_30s_bio_5.tif",
               "data/covariates/wc2.1_30s_bio/wc2.1_30s_bio_18.tif"))
  
clim <- coordSampleUnits |> 
  st_transform(crs=crs(worldClim)) |> 
  terra::extract(x = worldClim) |> 
  select(-ID)

#------------------------------- # just for proof of concept, I need to investigate why there are sea data/NA
no_seaData <- which((!is.na(clim$wc2.1_30s_bio_5)))

Y <- Y[no_seaData, ]
localityYear <- localityYear[no_seaData, ] 
coordSampleUnits <- coordSampleUnits[no_seaData, ]
clim <- clim[no_seaData, ]
forestInfo <- forestInfo[no_seaData, ]
clcInfo <- clcInfo[no_seaData, , drop = F]
#-----------------------------

XData <- forestInfo |> 
  select(-c(index, yr)) |> 
  bind_cols(clim, clcInfo) |> 
  as.data.frame() |> 
  mutate(Klass = as.factor(Klass))

row.names(XData) <- paste0(localityYear$karta, ":", localityYear$yr, ":", localityYear$punkt)

```

```{r}
zero_spp <-  which(colSums(Y) == 0)

Y <- Y[ , -zero_spp]
```

```{r}

## Heureka inputs

heureka <- T

if(heureka){
  forestRaw |>
    rename_with(~ paste0(., "_raw")) |> 
    slice(clcData) |>    
    slice(no_seaData) |> 
    bind_cols(XData) |> 
    write.csv("slu/input_heureka_forest.csv", row.names = F)
  
  coordSampleUnits |> 
    st_transform("EPSG:3006") |> 
    mutate(longSweref99 = sf::st_coordinates(.)[,1], latSweref99 = sf::st_coordinates(.)[,2]) |> 
    st_transform("EPSG:4326") |> 
    mutate(longWGS = sf::st_coordinates(.)[,1], latWGS = sf::st_coordinates(.)[,2]) |>
    st_drop_geometry() |> 
    write.csv("slu/input_heureka_coordSampleUnits.csv", row.names = F)
}




```


### Phylogenetic

First, we have to resolve names used in the phylogeny database and the bird survey.(BirdTree database)\[https://birdtree.org/\] The database come froms: (Jetz, W., G. H. Thomas, J. B. Joy, K. Hartmann, and A. O. Mooers. 2012. The global diversity of birds in space and time. Nature 491:444-448)\[https://www-nature-com.ludwig.lub.lu.se/articles/nature11631\]. There is no API, so write and retrieve manually. The species list from the database were web scrapping.

```{r}

birdTreeSpp <- read.csv("data/bird_tree/birdTree_spp.csv")
sppY <- colnames(Y)

sppResolved <- data.frame("scientificName" = NA, "bird_tree" = NA)

run <- F

if(run){

  for(i in 1:length(sppY)){
    spp.i <- sppY[i]
    
    isMissingSppTree <- !(spp.i %in% birdTreeSpp$species)
      
    if(isMissingSppTree){
        
      if(spp.i == "Corvus cornix"){
        
        synSppY.i <- "Corvus corone"
          
        }else if(spp.i == "Loxia bifasciata"){
          synSppY.i <- "Loxia leucoptera"
    
        }else if(spp.i == "Curruca cantillans"){
          synSppY.i <- "Sylvia cantillans"
    
        }else if(spp.i == "Columba livia f. domestica"){
          synSppY.i <- "Columba livia"
          
        }else{
          
        synSppY.i <- synonyms(spp.i, db = "nbn", rec_only = T, accepted = F, rank = "species", ask = F) |> 
          map_df(~ .x)
        
        if(ncol(synSppY.i) == 1 | ncol(synSppY.i) == 0){
          synSppY.i <- NA
        }else{
          synSppY.i <-  synSppY.i |> 
            select(nameString) |> 
            pull()
          synSppY.i <- (synSppY.i[synSppY.i %in% birdTreeSpp$species]) |> 
            unique()
        }
    
        }
      }else{
        synSppY.i <- spp.i
      }
     sppResolved[i,"scientificName"] <- spp.i
     sppResolved[i,"bird_tree"] <- synSppY.i
  }
  
  write.csv(sppResolved, "data/bird_tree/taxonomical_synonyms_birdtree.csv", row.names = F)
}else{
  
  sppResolved <- read.csv("data/bird_tree/taxonomical_synonyms_birdtree.csv")

}


# tree-pruner-79dc275b-d443-43a0-ad48-65f64e969c4f # 1000
# tree-pruner-cc685151-9887-452d-9dc0-01386d287412 # 100 removing NA data

Trees <- ape::read.nexus("data/bird_tree/n100_naRemoved/output.nex")

## MISSING. Consensus method (?)


phyloTree <- Trees[[sample(1:100, 1)]]


phyloTree$tip.label <- phyloTree$tip.label |> 
  str_replace(pattern = "_", " ")

#----------------
# remove spp
# phyloTree <- drop.tip(phyloTree, c("Anser_indicus", "Falco_vespertinus"))

#----------------

phyloTree$tip.label <- sppResolved$scientificName[match(phyloTree$tip.label, sppResolved$bird_tree)]

```

### Traits

```{r}
tr1 <- read.xlsx("data/traits/AVONET/TraitData/AVONET3_BirdTree.xlsx", sheet = 2) |> 
  rename(bird_tree = Species3) |>
  right_join(sppResolved, by = "bird_tree" ) |>  
  select(scientificName, Mass, Habitat, Habitat.Density, Trophic.Niche, Primary.Lifestyle, Migration)
 
TrData <- tr1 |>  
  as.data.frame()

row.names(TrData) <- TrData$scientificName 
 
TrData <- select(TrData, -scientificName)

TrData <- TrData[order(row.names(TrData)), ]

```

## Set up the model

### Study desing

```{r}
studyDesign <- localityYear |> 
  select(karta, yr, sampleUnit) |> 
  mutate(across(everything(), as.factor)) |> 
  as.data.frame()

row.names(studyDesign) <- paste0(studyDesign$karta, ":", studyDesign$yr, ":" ,studyDesign$sampleUnit)

xy <- coordSampleUnits |> 
  select(-c(yr, punkt, sampleUnit)) |> 
  st_transform("EPSG:4326")|>  
    mutate(
    long = sf::st_coordinates(.)[,1],
    lat = sf::st_coordinates(.)[,2]
  ) |> 
  st_drop_geometry() |> 
  distinct() |> 
  as.data.frame()

le <-  levels(studyDesign$karta)
xy.karta <-  matrix(nrow=length(le), ncol=2)  
rownames(xy.karta) <-  le

for(i in 1:length(le)){
  xy.cle <- xy[which(xy$karta == le[i]), c("long", "lat")]
  xy.karta[le[i],] <- colMeans(xy.cle)
}

colnames(xy.karta) <-  c("long", "lat")

write.csv(xy.karta, "xy.karta.csv", row.names = T)

```

### Random effects

```{r}

rL.sampleUnit <- HmscRandomLevel(units = levels(studyDesign$sampleUnit))
rL.year <- HmscRandomLevel(units = levels(studyDesign$yr))

```

Clean Environment

```{r}
toKeep <- c("model", "modeltype","XData", "XFormula", "TrData", "TrFormula", "phyloTree", "Y", "rL.sampleUnit", "rL.locality", "rL.year", "studyDesign",
            "sampleUnits", "transform_Y_to_abunCpres", "xy.karta")
rm(list = setdiff(ls(), toKeep))
gc()

```

```{r}

colnames(XData)

XFormula <- ~ Klass + AGE_XX_P + BEECHVOL_XX_P + CONTORTAVOL_XX_P + BIRCHVOL_XX_P + DECIDUOUSVOL_XX_P + HEIGHT_XX_P + OAKVOL_XX_P + PINEVOL_XX_P + SPRUCEVOL_XX_P + TOTALVOL_XX_P + BIOMASS_XX_P + poly(wc2.1_30s_bio_5, degree = 2) + poly(wc2.1_30s_bio_18, degree = 2)


```


```{r}
TrFormula <- ~ log(Mass) + Habitat +  Trophic.Niche + Habitat.Density + Primary.Lifestyle + Migration

```

### Define model

#### Three random levels and full gausian process


```{r}
rL.locality <-  HmscRandomLevel(sData = xy.karta, longlat = TRUE)
```


```{r}
m.abu = Hmsc(Y = Y,
 XData = XData, XFormula = XFormula,
 TrData = TrData, TrFormula = TrFormula,
 phyloTree = phyloTree,
 distr = "lognormal poisson", 
 studyDesign = studyDesign, ranLevels = list("karta" = rL.locality, "yr" = rL.year, "sampleUnit" = rL.sampleUnit)
 )

m.abuCpres = Hmsc(Y = transform_Y_to_abunCpres(Y),
 XData = XData, XFormula = XFormula,
 TrData = TrData, TrFormula = TrFormula,
 phyloTree = phyloTree,
 distr = "lognormal poisson", 
 studyDesign = studyDesign, ranLevels = list("karta" = rL.locality, "yr" = rL.year, "sampleUnit" = rL.sampleUnit)
 )

m.pa = Hmsc(Y = 1*(Y>0),
 XData = XData, XFormula = XFormula,
 TrData = TrData, TrFormula = TrFormula,
 phyloTree = phyloTree,
 distr = "probit", 
 studyDesign = studyDesign, ranLevels = list("karta" = rL.locality, "yr" = rL.year, "sampleUnit" = rL.sampleUnit)
 )
```


```{r}
model <- "sbsF_full"
modeltype <- c("abu", "aCp", "pa")

dir.create("models", showWarnings = F)
models <-  list(m.abu, m.abuCpres, m.pa )
names(models) <- paste0(model, "_", modeltype)
save(models, file = file.path("models", "unfitted_models_full.RData"))
```

#### To make the process faster: spatial level and temporal level only and NNGP in GPU proccessing

```{r}
rL.locality <-  HmscRandomLevel(sData = xy.karta, longlat = TRUE, sMethod = 'NNGP', nNeighbours = 8)
```


```{r}
m.abu = Hmsc(Y = Y,
 XData = XData, XFormula = XFormula,
 TrData = TrData, TrFormula = TrFormula,
 phyloTree = phyloTree,
 distr = "lognormal poisson",
 studyDesign = studyDesign,
 ranLevels = list("karta" = rL.locality, "yr" = rL.year)
 )

m.abuCpres = Hmsc(Y = transform_Y_to_abunCpres(Y),
 XData = XData, XFormula = XFormula,
 TrData = TrData, TrFormula = TrFormula,
 phyloTree = phyloTree,
 distr = "lognormal poisson", 
 studyDesign = studyDesign, 
 ranLevels = list("karta" = rL.locality, "yr" = rL.year)
 )

m.pa = Hmsc(Y = 1*(Y>0),
 XData = XData, XFormula = XFormula,
 TrData = TrData, TrFormula = TrFormula,
 phyloTree = phyloTree,
 distr = "probit", 
 studyDesign = studyDesign, 
 ranLevels = list("karta" = rL.locality, "yr" = rL.year)
 )
```


```{r}
model <- "sbsF_ngpp_2rl"
modeltype <- c("abu", "aCp", "pa")

dir.create("models", showWarnings = F)
models <-  list(m.abu, m.abuCpres, m.pa)
names(models) <- paste0(model, "_", modeltype)
save(models, file = file.path("models", "unfitted_models_NGPP.RData"))
```

#### Three random levels: spatial, samling unit, and temporal level and NNGP in GPU proccessing

```{r}
rL.locality <-  HmscRandomLevel(sData = xy.karta, longlat = TRUE, sMethod = 'NNGP', nNeighbours = 8)
```


```{r}
m.abu = Hmsc(Y = Y,
 XData = XData, XFormula = XFormula,
 TrData = TrData, TrFormula = TrFormula,
 phyloTree = phyloTree,
 distr = "lognormal poisson", 
 studyDesign = studyDesign, ranLevels = list("karta" = rL.locality, "yr" = rL.year, "sampleUnit" = rL.sampleUnit)
 )

m.abuCpres = Hmsc(Y = transform_Y_to_abunCpres(Y),
 XData = XData, XFormula = XFormula,
 TrData = TrData, TrFormula = TrFormula,
 phyloTree = phyloTree,
 distr = "lognormal poisson", 
 studyDesign = studyDesign, ranLevels = list("karta" = rL.locality, "yr" = rL.year, "sampleUnit" = rL.sampleUnit)
 )

m.pa = Hmsc(Y = 1*(Y>0),
 XData = XData, XFormula = XFormula,
 TrData = TrData, TrFormula = TrFormula,
 phyloTree = phyloTree,
 distr = "probit", 
 studyDesign = studyDesign, ranLevels = list("karta" = rL.locality, "yr" = rL.year, "sampleUnit" = rL.sampleUnit)
 )


m.abu$call

```

```{r}
model <- "sbsF_ngpp_3rl"
modeltype <- c("abu", "aCp", "pa")

dir.create("models", showWarnings = F)
models <-  list(m.abu, m.abuCpres, m.pa)
names(models) <- paste0(model, "_", modeltype)
save(models, file = file.path("models", "unfitted_models_NGPP_3rl.RData"))
```


```{r}
sampleMcmc(m.abu, samples=2)
```

```{r}
# Yx <- Y |> 
#   pivot_longer(
#     cols = everything(), # Pivotear todas las columnas excepto "id"
#     names_to = "especie",
#     values_to = "abundancia"
#   ) |> 
#   filter(abundancia != 0) |> 
```

